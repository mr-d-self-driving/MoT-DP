device:
  gpu_ids:
  - 0
dataloader:
  batch_size: 128
  num_workers: 8
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 2
  shuffle: true
obs_horizon: 4
pred_horizon: 10
action_horizon: 6
n_obs_steps: 4
ema:
  inv_gamma: 1.0
  max_value: 0.9999
  min_value: 0.0
  power: 0.75
  update_after_step: 0
optimizer:
  _target_: torch.optim.AdamW
  betas:
  - 0.9
  - 0.999
  eps: 1.0e-08
  lr: 5.0e-05  
  weight_decay: 1.0e-05
shape_meta:
  action:
    shape:
    - 2
  obs:
    agent_pos:
      shape:
      - 2
      type: low_dim
    image:
      shape:
      - 3
      - 96
      - 96
      type: rgb
    speed:
      shape:
      - 1
      type: low_dim
    theta:
      shape:
      - 1
      type: low_dim
    target_point:
      shape:
      - 2
      type: low_dim
enable_action_normalization: true
bev_encoder:
  pretrained_path: /home/wang/Project/MoT-DP/checkpoints/interfuser/lidar_bev_encoder_only.pth
  state_dim: 12
  feature_dim: 256
  use_group_norm: true
  freeze_backbone: false
  bev_input_size:
  - 448
  - 448
policy:
  input_dim: 2
  output_dim: 2
  horizon: 6
  n_obs_steps: 4
  cond_dim: 256
  obs_as_global_cond: true
  n_layer: 12
  n_head: 16
  n_emb: 1024
  p_drop_emb: 0.1
  p_drop_attn: 0.1
  causal_attn: true
  time_as_cond: true
  obs_as_cond: true
  n_cond_layers: 6
  action_horizon: 6

# Truncated Diffusion Configuration 
truncated_diffusion:
  num_train_timesteps: 1000        # Total timesteps for diffusion scheduler
  trunc_timesteps: 8               # Truncated timestep for adding noise during INFERENCE (V2 default)
  train_trunc_timesteps: 50        # Max timestep during TRAINING (DiffusionDrive uses 50)
  num_diffusion_steps: 2           # Number of denoising steps during inference (V2 default)
  eta: 1.0                         # 1.0 for stochastic multiplicative noise (V2 style), 0.0 for DDIM
  # Normalization: 2*(x + offset)/range - 1, mapping data to [-1, 1]
  # Based on action_stats: x: [-0.066, 74.045], y: [-17.526, 32.736]
  # Extended range with margin: x: [-1, 75], y: [-18, 34]
  norm_x_offset: 1.0               # x_min with margin = 1 (data min is -0.066)
  norm_x_range: 76.0               # x_max - x_min = 75 - (-1) = 76
  norm_y_offset: 18.0              # y_min with margin = 18 (data min is -17.526)  
  norm_y_range: 52.0               # y_max - y_min = 34 - (-18) = 52
  
training:
  num_epochs: 1000
  max_grad_norm: 1.0
  dataset_path: /mnt/data/pdm_lite_mini/tmp_data
  image_data_root: /mnt/data/pdm_lite_mini
  sample_interval: 1
  lr_final: 1e-7
  validation_freq: 5
  save_freq: 5
  early_stopping_patience: 10
  checkpoint_dir: /home/wang/Project/MoT-DP/checkpoints/carla_dit_best
logging:
  use_wandb: true
  wandb_project: carla-diffusion-policy
  run_name: carla_dit_optimized
  checkpoint_dir: /home/wang/Project/MoT-DP/checkpoints/carla_dit_best
  save_every: 5
  log_freq: 10
  wandb_entity: wangzhidong2000-nanyang-technological-university-singapore
  wandb_api_key: a0d403cb4dc1be3c5c7df4677a1b42d1c3e71b4f
eval:
  num_episodes: 10
  max_steps: 500
  success_threshold: 0.1
  eval_freq: 10
data_augmentation:
  enable: true
  image_noise_std: 0.02
  action_noise_std: 0.01
  random_crop: false
model_optimization:
  use_mixed_precision: true
  gradient_accumulation_steps: 2
  warmup_steps: 500
  lr_scheduler: cosine
action_stats:
  min:
  - -0.06638534367084503
  - -17.525903701782227
  max:
  - 74.04539489746094
  - 32.73622512817383
  mean:
  - 12.758530616760254
  - 0.354688435792923
  std:
  - 16.723825454711914
  - 2.5529885292053223
controller:
  turn_KP: 0.75
  turn_KI: 0.75
  turn_KD: 0.3
  turn_n: 40
  speed_KP: 5.0
  speed_KI: 0.5
  speed_KD: 1.0
  speed_n: 40
  aim_dist: 4.0
  angle_thresh: 0.3
  dist_thresh: 10.0
  brake_speed: 0.4
  brake_ratio: 1.1
  clip_delta: 0.25
  max_throttle: 0.75
